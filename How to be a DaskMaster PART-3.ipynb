{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to be a DaskMaster PART-3\n",
    "Implementing LabelEncoding from dask.preprocessing, dask_ml.xgboost on Dask DataFrame. Nail Dask in 15 minutes. Let’s see how it is done.\n",
    "This is my last blog on Dask. Reading these three parts won’t exactly get you to God-Level, but you will get a fair idea about how to become “The God” in Dask.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "import pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:54823</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>16.00 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:54823' processes=4 threads=4, memory=16.00 GB>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client, progress\n",
    "client = Client(n_workers=4, memory_limit='4GB')\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dd.read_parquet('zomato.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(data[\"url\"])\n",
    "del(data[\"address\"])\n",
    "del(data[\"menu_item\"])\n",
    "del(data[\"dish_liked\"])\n",
    "del(data[\"listed_in(type)\"])\n",
    "del(data[\"phone\"])\n",
    "del(data[\"reviews_list\"])\n",
    "del(data[\"rest_type\"])\n",
    "del(data[\"cuisines\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(data[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=client.persist(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"rate\"]=data[\"rate\"].str.replace(\"-\",\"650\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"approx_cost(for two people)\"]=data[\"approx_cost(for two people)\"].str.replace(\",\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"rate\"]=data[\"rate\"].str.replace(\"/5\",\"\")\n",
    "data[\"rate\"]=data[\"rate\"].str.replace(\"NEW\",\"0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ((data.isnull() | data.isna()).sum() * 100 / data.index.size).round(2).compute()\n",
    "data[\"location\"]=data[\"location\"].fillna(method=\"ffill\")\n",
    "data[\"approx_cost(for two people)\"]=data[\"approx_cost(for two people)\"].fillna(method=\"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=data.iloc[:,2]\n",
    "del(data[\"rate\"])\n",
    "X=data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=client.persist(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LabelEncoding:\n",
    "We have categorical values in our data. So, we will use LabelEncoder. Label Encoding is a technique to represent every value in a column with a number. We do Label Encoding because the model doesn’t understand strings. Therefore, we try to give numeric data in the model implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_ml.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder=LabelEncoder()\n",
    "encoder2=LabelEncoder()\n",
    "encoder3=LabelEncoder()\n",
    "encoder4=LabelEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code, we imported the Label Encoder from the dask_ml.preprocessing and not from the Sklearn. It’s important to understand that we are dealing with the Dask DataFrame and not with the ordinary pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(X[\"votes\"])\n",
    "del(X[\"approx_cost(for two people)\"])\n",
    "X2=X.values\n",
    "encod=encoder.fit_transform(X2[:,0]).compute()\n",
    "encod2=encoder2.fit_transform(X2[:,1]).compute()\n",
    "encod3=encoder3.fit_transform(X2[:,2]).compute()\n",
    "encod4=encoder4.fit_transform(X2[:,3]).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, in the above code, we deleted those columns from our dataset X which don’t need encoding (they were numeric by default). After that, we converted our X into an array by using the code in line number 3. Then, we simply implemented the fit_transform on every column in the dataset.\n",
    "* Now it is important to understand that the result which is computed by the Label Encoder is in the form of an array. It always returns an array-like structure so we will be converting every array back into the dask DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2=X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "encod=encoder.fit_transform(X2[:,0]).compute()\n",
    "encod2=encoder2.fit_transform(X2[:,1]).compute()\n",
    "encod3=encoder3.fit_transform(X2[:,2]).compute()\n",
    "encod4=encoder4.fit_transform(X2[:,3]).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "encod5=data[\"votes\"].values.compute()\n",
    "encod6=data[\"approx_cost(for two people)\"].values.compute()\n",
    "X=pd.DataFrame({'online_order': encod, 'book_table': encod2, \"location\":encod3,\"listed_in(city)\":encod4,\n",
    "              \"votes\":encod5,\"approx_cost(for two people)\":encod6},\n",
    "             columns=['online_order', 'book_table',\"location\",\"listed_in(city)\",\"votes\",\"approx_cost(for two people)\"])\n",
    "X=dd.from_pandas(X,npartitions=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We converted those array-like structures back into the pandas DataFrame. Then, from the pandas DataFrame, we converted it back into the Dask DataFrame by using npartition=100.\n",
    "Then, we try to clean our Target Y and then label encode that too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=client.persist(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=client.persist(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=Y.replace(\"None\",0.0)\n",
    "Y=Y.fillna(0)\n",
    "Y=Y.fillna(method=\"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodery=LabelEncoder()\n",
    "Y2=Y.astype(float)\n",
    "encodery=encoder.fit_transform(Y2).compute()\n",
    "encodery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23, 23, 20, ...,  0, 25, 16], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After this, we will change Y back into the dask DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=pd.DataFrame(encodery)\n",
    "Y=dd.from_pandas(Y,npartitions=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=client.persist(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=client.persist(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=client.persist(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we have both our X and Y ready for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.astype(float)\n",
    "Y=Y.astype(float)\n",
    "from dask_ml.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Implementation:\n",
    "We have successfully fitted the XGBRegressor model and got our predictions.\n",
    "Now, we will be converting our prediction into dask DataFrame and then calculate the r2_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import dask_ml\n",
    "from dask_ml.xgboost import XGBRegressor\n",
    "\n",
    "est = XGBRegressor()\n",
    "est.fit(X_train, y_train)\n",
    "prediction = est.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints=None,\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=1, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method=None, validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask_ml.xgboost import XGBRegressor\n",
    "\n",
    "est = XGBRegressor()\n",
    "est.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = est.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=dd.from_array(prediction,chunksize=500000)\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test,prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, the score is pretty impressive given the fact that we haven’t done any feature engineering or removed any outliers from the dataset. Why haven’t we done any of that? \n",
    "# Because our main goal was to Learn dask and implement it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8781144173343649"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test,prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
